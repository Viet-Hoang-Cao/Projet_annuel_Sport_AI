# Project â€” Plank Form Detection Using Mediapipe + MLP (Full & Keypoints)

## Introduction
Ce projet a pour objectif de dÃ©tecter automatiquement si un exercice de **plank** (gainage) est rÃ©alisÃ© en **bonne** ou **mauvaise** forme grÃ¢ce Ã  lâ€™IA.  
Pour cela, nous utilisons :

- **Mediapipe** pour extraire les points clÃ©s (landmarks) du corps humain
- **MLP (Multi-Layer Perceptron)** pour classer les postures
- Deux approches :  
  - **FULL landmarks (33 points Ã— 4 valeurs)**  
  - **KEYPOINTS (17 points essentiels Ã— 4 valeurs)**  

Le pipeline se compose de plusieurs notebooks, chacun ayant un rÃ´le prÃ©cis.

---

# Architecture gÃ©nÃ©rale

project_annuel/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ datasets/
â”‚ â”‚ â”œâ”€â”€ plank/
â”‚ â”‚ â”‚ â”œâ”€â”€ good/ # VidÃ©os bonne forme
â”‚ â”‚ â”‚ â”œâ”€â”€ bad/ # VidÃ©os mauvaise forme
â”‚
â”œâ”€â”€ core/
â”‚ â”œâ”€â”€ plank_model/
â”‚ â”‚ â”œâ”€â”€ data/
â”‚ â”‚ â”‚ â”œâ”€â”€ plank_dataset_full.csv
â”‚ â”‚ â”‚ â”œâ”€â”€ plank_dataset_keypoints.csv
â”‚ â”‚ â”‚ â”œâ”€â”€ scaler_full.pkl
â”‚ â”‚ â”‚ â”œâ”€â”€ scaler_keypoints.pkl
â”‚ â”‚ â”‚ â”œâ”€â”€ plank_test.csv
â”‚ â”‚ â”œâ”€â”€ model/
â”‚ â”‚ â”‚ â”œâ”€â”€ plank_mlp_full.pt
â”‚ â”‚ â”‚ â”œâ”€â”€ plank_mlp_keypoints.pt
â”‚ â”‚ â”œâ”€â”€ notebooks/
â”‚ â”‚ â”‚ â”œâ”€â”€ data_plank.ipynb
â”‚ â”‚ â”‚ â”œâ”€â”€ scaler_and_test_plank.ipynb
â”‚ â”‚ â”‚ â”œâ”€â”€ mlp_train_full.ipynb
â”‚ â”‚ â”‚ â”œâ”€â”€ mlp_train_keypoints.ipynb
â”‚ â”‚ â”‚ â”œâ”€â”€ realtime_plank_mlp.ipynb
â”‚
â””â”€â”€ README.md

---

# Notebooks dÃ©taillÃ©s

## `data_plank.ipynb` â€” Extraction des landmarks

### Objectif
Convertir les vidÃ©os (Good / Bad Form) en fichiers CSV exploitables pour lâ€™entraÃ®nement des modÃ¨les.

### Librairies utilisÃ©es
| Librairie | RÃ´le |
|----------|------|
| `mediapipe` | DÃ©tection des 33 points du squelette humain |
| `opencv (cv2)` | Lecture vidÃ©o frame par frame |
| `pandas` | Construction des datasets CSV |
| `numpy` | Manipulation numÃ©rique |
| `glob` | Parcours automatique des dossiers |
| `os` | CrÃ©ation des dossiers |

### Fonctionnement
Pour chaque vidÃ©o :

1. Lecture des frames
2. Passage dans Mediapipe â†’ extraction des landmarks
3. Extraction de :
   - **FULL (33 points)** â†’ 132 valeurs (x, y, z, visibility)
   - **KEYPOINTS (17 points)** â†’ 68 valeurs
4. Ajout du `label` (0 = good, 1 = bad)
5. Sauvegarde dans :
   - `plank_dataset_full.csv`
   - `plank_dataset_keypoints.csv`

### Pourquoi FULL + KEYPOINTS ?
- FULL = plus de prÃ©cision, mais plus fragile (bruit, occlusions)
- KEYPOINTS = robustesse + performance MLP optimisÃ©e  
â†’ Lâ€™auteur initial de GitHub utilise aussi des keypoints essentiels.

---

## `scaler_and_test_plank.ipynb` â€” Standardisation + Dataset Test

### Objectif
PrÃ©parer les donnÃ©es pour lâ€™entraÃ®nement du modÃ¨le.

### RÃ´le du scaler
Les valeurs des landmarks ont des Ã©chelles diffÃ©rentes :

- x â‰ˆ 0.3
- y â‰ˆ 0.7
- z â‰ˆ -0.03
- visibilitÃ© â‰ˆ 0.9

âž¡ Sans normalisation, le modÃ¨le favoriserait les colonnes les plus grandes.

### Actions rÃ©alisÃ©es
1. Chargement des deux datasets
2. SÃ©paration X / y
3. Application de `StandardScaler()` :
   - moyenne = 0
   - variance = 1
4. Sauvegarde :
   - `scaler_full.pkl`
   - `scaler_keypoints.pkl`
5. GÃ©nÃ©ration dâ€™un fichier test :
   - `plank_test.csv`

### Pourquoi cette Ã©tape est essentielle ?
Le scaler doit Ãªtre **rÃ©utilisÃ©** pendant :
- lâ€™entraÃ®nement
- la dÃ©tection rÃ©elle
- lâ€™infÃ©rence sur vidÃ©o  

Sans scaler â†’ le modÃ¨le donnerait des prÃ©dictions fausses.

---

## `mlp_train_full.ipynb` â€” ModÃ¨le MLP Full Landmarks  
## `mlp_train_keypoints.ipynb` â€” ModÃ¨le MLP Keypoints

### Objectif
EntraÃ®ner deux modÃ¨les diffÃ©rents :

- un avec **132 features**  
- un avec **68 features**

### Pourquoi un MLP ?
Un MLP est adaptÃ© quand :

- Les donnÃ©es sont tabulaires (CSV)
- Lâ€™ordre temporel nâ€™est pas essentiel  
  (un plank est statique â†’ pas besoin de LSTM)
- Le dataset est petit
- On veut un modÃ¨le rapide et lÃ©ger

Un MLP est :
- simple
- efficace
- rapide Ã  entraÃ®ner
- excellent pour la classification binaire posture

### ðŸ›  Actions du notebook
1. Chargement du dataset
2. Application du scaler
3. Split train/test
4. DÃ©finition du modÃ¨le MLP PyTorch
5. EntraÃ®nement :
   - forward pass
   - backward pass
   - optimisation Adam
6. Calcul de lâ€™accuracy
7. Sauvegarde :
   - `plank_mlp_full.pt`
   - `plank_mlp_keypoints.pt`

### Notes importantes
- Le modÃ¨le keypoints est souvent plus stable.
- Le FULL peut sur-apprendre sur un petit dataset.

---

## `realtime_plank_mlp.ipynb` â€” DÃ©tection VidÃ©o / Webcam

### Objectif
Tester le modÃ¨le en conditions rÃ©elles.

### Fonctionnement
1. Chargement :
   - modÃ¨le MLP
   - scaler correspondant
2. Ouverture :
   - dâ€™une vidÃ©o (`cv2.VideoCapture(path)`)
   - ou de la webcam (`cv2.VideoCapture(0)`)
3. Extraction des keypoints en temps rÃ©el via Mediapipe
4. Transformation avec le scaler
5. Passage dans le modÃ¨le MLP â†’ prÃ©diction
6. Affichage OpenCV :
   - classe : **GOOD** ou **BAD**
   - probabilitÃ©
   - skeleton annotÃ©

### Ã€ modifier si tu veux tester une vidÃ©o
```python
cap = cv2.VideoCapture("chemin/vers/la/video.mp4")

Points importants

Mediapipe peut manquer des frames â†’ normal

Le scaler doit Ãªtre appliquÃ© AVANT le modÃ¨le

La qualitÃ© vidÃ©o influence Ã©normÃ©ment la dÃ©tection