{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7af2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc8e00d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3935, 69)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>nose_x</th>\n",
       "      <th>nose_y</th>\n",
       "      <th>nose_z</th>\n",
       "      <th>nose_v</th>\n",
       "      <th>left_shoulder_x</th>\n",
       "      <th>left_shoulder_y</th>\n",
       "      <th>left_shoulder_z</th>\n",
       "      <th>left_shoulder_v</th>\n",
       "      <th>right_shoulder_x</th>\n",
       "      <th>...</th>\n",
       "      <th>right_heel_z</th>\n",
       "      <th>right_heel_v</th>\n",
       "      <th>left_foot_index_x</th>\n",
       "      <th>left_foot_index_y</th>\n",
       "      <th>left_foot_index_z</th>\n",
       "      <th>left_foot_index_v</th>\n",
       "      <th>right_foot_index_x</th>\n",
       "      <th>right_foot_index_y</th>\n",
       "      <th>right_foot_index_z</th>\n",
       "      <th>right_foot_index_v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.830130</td>\n",
       "      <td>0.351851</td>\n",
       "      <td>-0.025262</td>\n",
       "      <td>0.999119</td>\n",
       "      <td>0.716336</td>\n",
       "      <td>0.299204</td>\n",
       "      <td>0.223861</td>\n",
       "      <td>0.993920</td>\n",
       "      <td>0.721056</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051480</td>\n",
       "      <td>0.831482</td>\n",
       "      <td>0.031709</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>0.180639</td>\n",
       "      <td>0.640694</td>\n",
       "      <td>0.002836</td>\n",
       "      <td>0.391812</td>\n",
       "      <td>-0.140807</td>\n",
       "      <td>0.875498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.827971</td>\n",
       "      <td>0.351691</td>\n",
       "      <td>-0.026928</td>\n",
       "      <td>0.999033</td>\n",
       "      <td>0.716258</td>\n",
       "      <td>0.299152</td>\n",
       "      <td>0.236521</td>\n",
       "      <td>0.993811</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075619</td>\n",
       "      <td>0.827558</td>\n",
       "      <td>0.033213</td>\n",
       "      <td>0.375629</td>\n",
       "      <td>0.180146</td>\n",
       "      <td>0.626701</td>\n",
       "      <td>0.011874</td>\n",
       "      <td>0.391841</td>\n",
       "      <td>-0.171767</td>\n",
       "      <td>0.869638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.826663</td>\n",
       "      <td>0.350897</td>\n",
       "      <td>-0.034896</td>\n",
       "      <td>0.998833</td>\n",
       "      <td>0.717475</td>\n",
       "      <td>0.299097</td>\n",
       "      <td>0.238402</td>\n",
       "      <td>0.993522</td>\n",
       "      <td>0.722325</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074106</td>\n",
       "      <td>0.822614</td>\n",
       "      <td>0.033985</td>\n",
       "      <td>0.374774</td>\n",
       "      <td>0.204634</td>\n",
       "      <td>0.610258</td>\n",
       "      <td>0.014278</td>\n",
       "      <td>0.392639</td>\n",
       "      <td>-0.170130</td>\n",
       "      <td>0.862897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.825896</td>\n",
       "      <td>0.350415</td>\n",
       "      <td>-0.040929</td>\n",
       "      <td>0.998722</td>\n",
       "      <td>0.717678</td>\n",
       "      <td>0.299094</td>\n",
       "      <td>0.238142</td>\n",
       "      <td>0.993332</td>\n",
       "      <td>0.722549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060950</td>\n",
       "      <td>0.820857</td>\n",
       "      <td>0.037479</td>\n",
       "      <td>0.374753</td>\n",
       "      <td>0.218800</td>\n",
       "      <td>0.599725</td>\n",
       "      <td>0.018048</td>\n",
       "      <td>0.393976</td>\n",
       "      <td>-0.154337</td>\n",
       "      <td>0.859343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.825994</td>\n",
       "      <td>0.350126</td>\n",
       "      <td>-0.047208</td>\n",
       "      <td>0.998716</td>\n",
       "      <td>0.717702</td>\n",
       "      <td>0.299497</td>\n",
       "      <td>0.231987</td>\n",
       "      <td>0.993373</td>\n",
       "      <td>0.722911</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061091</td>\n",
       "      <td>0.820887</td>\n",
       "      <td>0.038908</td>\n",
       "      <td>0.374778</td>\n",
       "      <td>0.217422</td>\n",
       "      <td>0.595844</td>\n",
       "      <td>0.021588</td>\n",
       "      <td>0.394186</td>\n",
       "      <td>-0.154317</td>\n",
       "      <td>0.858819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label    nose_x    nose_y    nose_z    nose_v  left_shoulder_x  \\\n",
       "0      0  0.830130  0.351851 -0.025262  0.999119         0.716336   \n",
       "1      0  0.827971  0.351691 -0.026928  0.999033         0.716258   \n",
       "2      0  0.826663  0.350897 -0.034896  0.998833         0.717475   \n",
       "3      0  0.825896  0.350415 -0.040929  0.998722         0.717678   \n",
       "4      0  0.825994  0.350126 -0.047208  0.998716         0.717702   \n",
       "\n",
       "   left_shoulder_y  left_shoulder_z  left_shoulder_v  right_shoulder_x  ...  \\\n",
       "0         0.299204         0.223861         0.993920          0.721056  ...   \n",
       "1         0.299152         0.236521         0.993811          0.721311  ...   \n",
       "2         0.299097         0.238402         0.993522          0.722325  ...   \n",
       "3         0.299094         0.238142         0.993332          0.722549  ...   \n",
       "4         0.299497         0.231987         0.993373          0.722911  ...   \n",
       "\n",
       "   right_heel_z  right_heel_v  left_foot_index_x  left_foot_index_y  \\\n",
       "0     -0.051480      0.831482           0.031709           0.376000   \n",
       "1     -0.075619      0.827558           0.033213           0.375629   \n",
       "2     -0.074106      0.822614           0.033985           0.374774   \n",
       "3     -0.060950      0.820857           0.037479           0.374753   \n",
       "4     -0.061091      0.820887           0.038908           0.374778   \n",
       "\n",
       "   left_foot_index_z  left_foot_index_v  right_foot_index_x  \\\n",
       "0           0.180639           0.640694            0.002836   \n",
       "1           0.180146           0.626701            0.011874   \n",
       "2           0.204634           0.610258            0.014278   \n",
       "3           0.218800           0.599725            0.018048   \n",
       "4           0.217422           0.595844            0.021588   \n",
       "\n",
       "   right_foot_index_y  right_foot_index_z  right_foot_index_v  \n",
       "0            0.391812           -0.140807            0.875498  \n",
       "1            0.391841           -0.171767            0.869638  \n",
       "2            0.392639           -0.170130            0.862897  \n",
       "3            0.393976           -0.154337            0.859343  \n",
       "4            0.394186           -0.154317            0.858819  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\PORTABLE\\Desktop\\projet_annuel\\core\\plank_model\\data\\plank_dataset_keypoints.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6da418d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: torch.Size([3148, 68]) TEST: torch.Size([787, 68])\n",
      "Label distrib train: (array([0., 1.], dtype=float32), array([2145, 1003]))\n",
      "Label distrib test : (array([0., 1.], dtype=float32), array([536, 251]))\n"
     ]
    }
   ],
   "source": [
    "# Load ALREADY-SPLIT datasets (SOURCE OF TRUTH)\n",
    "train_df = pd.read_csv(r\"C:\\Users\\PORTABLE\\Desktop\\projet_annuel\\core/plank_model/data/plank_train_keypoints.csv\")\n",
    "test_df  = pd.read_csv(r\"C:\\Users\\PORTABLE\\Desktop\\projet_annuel\\core/plank_model/data/plank_test_keypoints.csv\")\n",
    "\n",
    "X_train = train_df.drop(\"label\", axis=1).values.astype(np.float32)\n",
    "y_train = train_df[\"label\"].values.astype(np.float32)\n",
    "\n",
    "X_test = test_df.drop(\"label\", axis=1).values.astype(np.float32)\n",
    "y_test = test_df[\"label\"].values.astype(np.float32)\n",
    "\n",
    "# Fit scaler ONLY on TRAIN\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "# Save scaler for live\n",
    "with open(r\"C:\\Users\\PORTABLE\\Desktop\\projet_annuel\\core/plank_model/model/scaler_keypoints.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Torch tensors\n",
    "X_train = torch.tensor(X_train)\n",
    "y_train = torch.tensor(y_train)\n",
    "\n",
    "X_test = torch.tensor(X_test)\n",
    "y_test = torch.tensor(y_test)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
    "test_loader  = DataLoader(TensorDataset(X_test, y_test), batch_size=32)\n",
    "\n",
    "# SANITY CHECK\n",
    "print(\"TRAIN:\", X_train.shape, \"TEST:\", X_test.shape)\n",
    "print(\"Label distrib train:\", np.unique(y_train.numpy(), return_counts=True))\n",
    "print(\"Label distrib test :\", np.unique(y_test.numpy(), return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f98c2685",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Keypoints(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = MLP_Keypoints(input_dim=X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e50c2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caf099f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Loss: 0.2574\n",
      "Epoch 2/20 - Loss: 0.0712\n",
      "Epoch 3/20 - Loss: 0.0339\n",
      "Epoch 4/20 - Loss: 0.0200\n",
      "Epoch 5/20 - Loss: 0.0139\n",
      "Epoch 6/20 - Loss: 0.0097\n",
      "Epoch 7/20 - Loss: 0.0093\n",
      "Epoch 8/20 - Loss: 0.0094\n",
      "Epoch 9/20 - Loss: 0.0041\n",
      "Epoch 10/20 - Loss: 0.0057\n",
      "Epoch 11/20 - Loss: 0.0031\n",
      "Epoch 12/20 - Loss: 0.0032\n",
      "Epoch 13/20 - Loss: 0.0055\n",
      "Epoch 14/20 - Loss: 0.0032\n",
      "Epoch 15/20 - Loss: 0.0038\n",
      "Epoch 16/20 - Loss: 0.0009\n",
      "Epoch 17/20 - Loss: 0.0014\n",
      "Epoch 18/20 - Loss: 0.0018\n",
      "Epoch 19/20 - Loss: 0.0107\n",
      "Epoch 20/20 - Loss: 0.0008\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        preds = model(xb).squeeze()\n",
    "        loss = loss_fn(preds, yb)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {total_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e609fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(X_test).squeeze()\n",
    "    preds = torch.sigmoid(preds)\n",
    "    preds = (preds > 0.5).float()\n",
    "\n",
    "accuracy = (preds == y_test).float().mean()\n",
    "print(\"Accuracy:\", accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96e1316c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 - Train Loss: 0.0005 - Test Loss: 0.0000\n",
      "Epoch 2/15 - Train Loss: 0.0007 - Test Loss: 0.0000\n",
      "Epoch 3/15 - Train Loss: 0.0004 - Test Loss: 0.0000\n",
      "Epoch 4/15 - Train Loss: 0.0005 - Test Loss: 0.0001\n",
      "Epoch 5/15 - Train Loss: 0.0010 - Test Loss: 0.0001\n",
      "Epoch 6/15 - Train Loss: 0.0004 - Test Loss: 0.0001\n",
      "Epoch 7/15 - Train Loss: 0.0005 - Test Loss: 0.0030\n",
      "Epoch 8/15 - Train Loss: 0.0011 - Test Loss: 0.0013\n",
      "Epoch 9/15 - Train Loss: 0.0015 - Test Loss: 0.0002\n",
      "Epoch 10/15 - Train Loss: 0.0005 - Test Loss: 0.0000\n",
      "Epoch 11/15 - Train Loss: 0.0002 - Test Loss: 0.0000\n",
      "Epoch 12/15 - Train Loss: 0.0001 - Test Loss: 0.0000\n",
      "Epoch 13/15 - Train Loss: 0.0001 - Test Loss: 0.0000\n",
      "Epoch 14/15 - Train Loss: 0.0002 - Test Loss: 0.0000\n",
      "Epoch 15/15 - Train Loss: 0.0022 - Test Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 15\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "best_loss = float(\"inf\")\n",
    "patience = 2\n",
    "wait = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        preds = model(xb).squeeze()\n",
    "        loss = loss_fn(preds, yb)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    train_losses.append(total_loss / len(train_loader))\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            preds = model(xb).squeeze()\n",
    "            loss = loss_fn(preds, yb)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(test_loader)\n",
    "    test_losses.append(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Train Loss: {train_losses[-1]:.4f} - Test Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68e57a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle KEYPOINTS sauvegardé.\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), r\"C:\\Users\\PORTABLE\\Desktop\\projet_annuel\\core\\plank_model\\model\\plank_mlp_keypoints.pt\")\n",
    "print(\"Modèle KEYPOINTS sauvegardé.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
