{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4f828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_lstm_plank.ipynb\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Charger les séquences\n",
    "# -----------------------------\n",
    "data = np.load(\"plank_model/data/plank_sequences.npz\")\n",
    "X = data[\"X\"]\n",
    "y = data[\"y\"]\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Créer le DataLoader PyTorch\n",
    "# -----------------------------\n",
    "batch_size = 32\n",
    "dataset = TensorDataset(torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.long))\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Définir le modèle LSTM\n",
    "# -----------------------------\n",
    "class PlankLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=128, num_layers=2, num_classes=1, dropout=0.3):\n",
    "        super(PlankLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, batch_first=True, dropout=dropout if num_layers>1 else 0)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]  # dernière frame\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "input_size = X.shape[2]  # nombre de colonnes landmarks\n",
    "model = PlankLSTM(input_size)\n",
    "print(model)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Définir la perte et l’optimizer\n",
    "# -----------------------------\n",
    "criterion = nn.BCELoss()  # binary classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Entraînement\n",
    "# -----------------------------\n",
    "epochs = 20\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.float().unsqueeze(1).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    val_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.float().to(device), yb.float().unsqueeze(1).to(device)\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {total_loss/len(train_loader):.4f} - Val Loss: {val_loss/len(val_loader):.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Sauvegarde du modèle\n",
    "# -----------------------------\n",
    "os.makedirs(\"plank_model/model\", exist_ok=True)\n",
    "torch.save(model.state_dict(), \"plank_model/model/plank_model.pth\")\n",
    "print(\"Modèle sauvegardé → plank_model/model/plank_model.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
